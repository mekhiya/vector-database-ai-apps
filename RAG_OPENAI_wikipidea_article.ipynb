{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXO106mxYYPZg4gJSwmarO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhiya/vector-database-ai-apps/blob/main/RAG_OPENAI_wikipidea_article.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "whl8zjnza68U"
      },
      "outputs": [],
      "source": [
        "# RAG\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "# requirements file\n",
        "# note which revision of python, for example 3.9.6\n",
        "# in this file, insert all the pip install needs, include revision\n",
        "\n",
        "#for example:\n",
        "#torch==2.0.1\n",
        "#matplotlib==3.7.2\n",
        "\n",
        "python-dotenv==1.0.0\n",
        "\n",
        "numpy==1.25.2\n",
        "pandas==2.1.3\n",
        "scikit-learn==1.3.2\n",
        "sentence-transformers==2.2.2\n",
        "matplotlib==3.8.2\n",
        "torch==2.1.1\n",
        "\n",
        "langchain==0.0.346\n",
        "openai==0.28.1 ## From the notebooks\n",
        "\n",
        "pinecone-client==3.0.0dev4\n",
        "pinecone-datasets==0.5.0rc11\n",
        "pinecone-text==0.7.1\n",
        "\n",
        "tiktoken==0.5.2\n",
        "tqdm==4.66.1\n",
        "\n",
        "datasets==2.15.0\n",
        "deepface==0.0.79"
      ],
      "metadata": {
        "id": "mWLZ9qaWLzeG"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "RLzwJNqSLzao"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile DLAIUtils.py\n",
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "class Utils:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def create_dlai_index_name(self, index_name):\n",
        "    openai_key = ''\n",
        "    if self.is_colab(): # google colab\n",
        "      from google.colab import userdata\n",
        "      openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "    else: # jupyter notebook\n",
        "      openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    return f'{index_name}-{openai_key[-36:].lower().replace(\"_\", \"-\")}'\n",
        "\n",
        "  def is_colab(self):\n",
        "    return 'google.colab' in sys.modules\n",
        "\n",
        "  def get_openai_api_key(self):\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "    return os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "  def get_pinecone_api_key(self):\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "    return os.getenv(\"PINECONE_API_KEY\")"
      ],
      "metadata": {
        "id": "1XMMm1_tLzYA"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python DLAIUtils.py"
      ],
      "metadata": {
        "id": "KTDiG_3bLzVS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install -U sentence-transformers\n",
        "!pip install pinecone-client"
      ],
      "metadata": {
        "id": "vCfsIr59LzSe"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "UlWjyROvQKgm"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from DLAIUtils import Utils\n",
        "import DLAIUtils\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "import ast\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TzTEHdppLzPj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "RceI0DmKLzMp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils = Utils()\n",
        "PINECONE_API_KEY = utils.get_pinecone_api_key()"
      ],
      "metadata": {
        "id": "phzYBZRTLzJ_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils = Utils()\n",
        "PINCECODE_API_KEY = utils.get_pinecone_api_key()\n",
        "OPENAI_API_KEY = utils.get_openai_api_key()\n",
        "\n",
        "print(PINCECODE_API_KEY)\n",
        "print(OPENAI_API_KEY)\n",
        "OPENAI_API_KEY[-36:].lower().replace(\"_\", \"-\")"
      ],
      "metadata": {
        "id": "WXBFyXQLQvp7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX_NAME = 'dl-ai' + OPENAI_API_KEY[-36:].lower().replace(\"_\", \"-\")\n",
        "INDEX_NAME"
      ],
      "metadata": {
        "id": "5eWfxaS1Q0L2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "  pinecone.delete_index(INDEX_NAME)\n",
        "  print(f'Deleting Index {INDEX_NAME}')\n",
        "print(INDEX_NAME)"
      ],
      "metadata": {
        "id": "lKU91YybLzHK"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.create_index(name=INDEX_NAME,dimension=1536,metric='cosine',\n",
        "                      spec=ServerlessSpec(cloud='aws',region='us-west-2'))\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "id": "fA-47p73LzES"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget -q -O wiki.csv.zip \"https://www.dropbox.com/scl/fi/yxzmsrv2sgl249zcspeqb/lesson2-wiki.csv.zip?rlkey=paehnoxjl3s5x53d1bedt4pmc&dl=0\"\n",
        "# !mkdir sample_data\n",
        "# !unzip wiki.csv.zip -d sample_data/"
      ],
      "metadata": {
        "id": "gF9A7yf3LzBa"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_articles_num = 500\n",
        "df = pd.read_csv('./sample_data/wiki.csv', nrows=max_articles_num)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DGJTyKq9Ly-n"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepped = []\n",
        "print(df.shape[0])\n",
        "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "  meta = ast.literal_eval(row['metadata'])\n",
        "  prepped.append({'id':row['id'],\n",
        "                  'values':ast.literal_eval(row['values']),\n",
        "                  'metadata':meta})\n",
        "  if len(prepped) >= 200:\n",
        "    index.upsert(prepped)\n",
        "    prepped = []"
      ],
      "metadata": {
        "id": "RgRb143sUu1d"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "-lIhFLhSUux_"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(articles, model=\"text-embedding-ada-002\"):\n",
        "   return openai_client.embeddings.create(input = articles, model=model)"
      ],
      "metadata": {
        "id": "dqgqwGutUuvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = utils.get_openai_api_key()\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "def get_embeddings(articles, model='text-embedding-ada-002'):\n",
        "  return openai_client.embeddings.create(input=articles, model=model)"
      ],
      "metadata": {
        "id": "Sb0AKQ8aUusa"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quering vector db to fetch grounded info\n",
        "query = \"what is great wall of china?\"\n",
        "\n",
        "embed = get_embeddings([query])\n",
        "res = index.query(vector=embed.data[0].embedding, top_k=3, include_metadata=True)\n",
        "text = [r['metadata']['text'] for r in res['matches']]\n",
        "print('\\n'.join(text))"
      ],
      "metadata": {
        "id": "vSy2ZuFuUumZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building prompt\n",
        "query = \"write an article titled: what is great wall of china?\"\n",
        "embed = get_embeddings([query])\n",
        "res = index.query(vector=embed.data[0].embedding, top_k=3, include_metadata=True)\n",
        "\n",
        "contexts = [\n",
        "    x['metadata']['text'] for x in res['matches']\n",
        "]\n",
        "\n",
        "prompt_start = (\n",
        "    \"Answer the question base on the context below. \\n\\n\" +\n",
        "    \"Context:\\n\"\n",
        ")\n",
        "\n",
        "prompt_end = (\n",
        "    f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
        ")\n",
        "\n",
        "prompt = (\n",
        "    prompt_start + \"\\n\\n---\\n\\n\".join(contexts) +\n",
        "    prompt_end\n",
        ")\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "qsfNxPY6lI87"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = openai_client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=636,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=None\n",
        ")\n",
        "print('-' * 80)\n",
        "print(res.choices[0].text)"
      ],
      "metadata": {
        "id": "EfWF9b7HlJlz"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}